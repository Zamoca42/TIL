{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zamoca42/TIL/blob/main/keras_units_optimizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InWSe-2xGoaQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# and, or, xor gate\n",
        "\n",
        "X_train=[[0,0],[0,1],[1,0],[1,1]]\n",
        "# Y_train=[0,0,0,1] 'and' gate\n",
        "# Y_train=[0,1,1,1] # 'or' gate\n",
        "Y_train=[0,1,1,0] # 'xor' gate\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(units=1, activation='sigmoid', input_shape=[2]),\n",
        "])\n",
        "\n",
        "opt = keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(X_train,Y_train, batch_size=1, epochs=1000, shuffle = True, verbose = 1)\n",
        "\n",
        "print(model.weights)\n",
        "print(\"0xor0 -> \",model.predict([[0,0]]))\n",
        "print(\"0xor1 -> \",model.predict([[0,1]]))\n",
        "print(\"1xor0 -> \",model.predict([[1,0]]))\n",
        "print(\"1xor1 -> \",model.predict([[1,1]]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXv8USzsGuig"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# and, or, xor gate\n",
        "\n",
        "# input\n",
        "X_train=[[0,0],[0,1],[1,0],[1,1]]\n",
        "\n",
        "# output\n",
        "# Y_train=[0,0,0,1] 'and' gate\n",
        "# Y_train=[0,1,1,1] # 'or' gate\n",
        "Y_train=[0,1,1,0] # 'xor' gate\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(units=2, activation='sigmoid', input_shape=[2]),\n",
        "    keras.layers.Dense(units=3, activation='sigmoid'),\n",
        "    keras.layers.Dense(units=1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "# units = Neuron의 갯수\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.1)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(X_train,Y_train, batch_size=4, epochs=1000, shuffle = True, verbose = 0)\n",
        "\n",
        "print(model.weights)\n",
        "print(\"0 xor 0 -> \",model.predict([[0,0]]))\n",
        "print(\"0 xor 1 -> \",model.predict([[0,1]]))\n",
        "print(\"1 xor 0 -> \",model.predict([[1,0]]))\n",
        "print(\"1 xor 1 -> \",model.predict([[1,1]]))\n",
        "\n",
        "# https://keras.io/api/optimizers/adam/\n",
        "# https://amber-chaeeunk.tistory.com/23"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPbvWpgo2LO16vPHvPaEky0",
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
