{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLoSJSjkx+MFP5HZdnv+Nl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zamoca42/TIL/blob/main/AI/final_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Summary\n",
        "\n",
        "## Train/Test/Validation data\n",
        "\n",
        "- Train 세트 : 훈련을 위해 사용되는 데이터\n",
        "- Test 세트 : 성능 평가를 위한 데이터\n",
        "- Validation 세트 : 훈련 데이터에서 가져온 데이터로 성능 검증에 쓰임\n",
        "\n",
        "## Overfitting\n",
        "\n",
        "- 측정에 의한 데이터는 노이즈가 있을 수 있고 그 노이즈까지 학습해버리는 것을 과적합이라고한다.\n",
        "\n",
        "- 적당한 loss에서 끊어 줄 필요가 있고, validation set이 필요한 이유\n",
        "\n",
        "- validation loss에서 갑자기 상승하는 구간을 통해 적당한 epoch를 설정가능\n",
        "\n",
        "- 참고 \n",
        "  - https://untitledtblog.tistory.com/m/68 -> 과적합\n",
        "  - https://ko.wikipedia.org/wiki/%EA%B3%BC%EC%A0%81%ED%95%A9 -> 로지스틱에서 과적합\n",
        "\n",
        "## Normalization/Standardization/Regularization\n",
        "\n",
        "- Normalization (정규화)\n",
        "  - Data를 0과 1사이의 값으로 재조정\n",
        "  - Input 간의 값 차이가 크면 학습이 잘 안됨\n",
        "\t  - 데이터크기가 100배 크면 Error도 100배 큼\n",
        "\n",
        "- Standardization (표준화)\n",
        "\n",
        "  - 평균을 0으로 하고 표준편차를 1로 만듭니다\n",
        "  - 참고\n",
        "    - https://m.blog.naver.com/mrp/221672080759\n",
        "\n",
        "- Regularization (일반화)\n",
        "\n",
        "  - overfitting을 막아주는 방법\n",
        "  - 특정 가중치의 값들이 커져서 결과가 나빠지는 경우를 방지하기 위해 간단한 쪽으로 선택을 유도하는 방식\n",
        "  - 참고\n",
        "    - https://m.blog.naver.com/laonple/220527647084\n",
        "\n",
        "## Softamx vs Sigmoid\n",
        "\n",
        "|Softmax Function|Sigmoid Function|\n",
        "|---|---|\n",
        "|logistic regression에서 </br> multi-classification에서 사용| logistic regression에서 </br> binary-classification에서 사용|\n",
        "|확률의 총 합 = 1| 확률의 총 합은 1이 아님|\n",
        "|출력층에서 사용됨(확률 표현)| Activation함수로 사용 될 수 있음 </br> (이제는 ReLu사용)|\n",
        "|큰 출력 값은 그 class에 해당할 </br> 가능성이 높다는 것을 뜻하며 실제 확률을 나타냄| 큰 출력 값은 그 class에 해당할</br> 가능성이 높지만 실제 확률 값을 나타내는 것은 아님|\n",
        "\n",
        "## CNN\n",
        "\n",
        "- https://hobinjeong.medium.com/cnn%EC%97%90%EC%84%9C-pooling%EC%9D%B4%EB%9E%80-c4e01aa83c83\n",
        "\n",
        "```python\n",
        "# Conv2D(filter,kernel_size,strides,activation,input_shape)\n",
        "# filter = 필터 개수\n",
        "# kernel_size = 필터의 크기\n",
        "# strides = 풀링 필터를 이동시키는 간격\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters = 32, kernel_size=3, strides = (1,1),activation='relu', input_shape=(28,28,1)),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Flatten(), # **2D 데이터를 1D 데이터로 변환\n",
        "    keras.layers.Dense(units=64, activation='relu'),\n",
        "    keras.layers.Dense(units=10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 모델 컴파일\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# 훈련하기\n",
        "# hist = model.fit(X_train, Y_train, epochs=5, validation_split=0.2, verbose = 1)\n",
        "hist = model.fit(X_train, Y_train, batch_size = 8, epochs=5, validation_split=0.2, verbose = 1)\n",
        "\n",
        "```\n",
        "\n",
        "## CNN 사용방법 - conv2D 파라미터 개수\n",
        "\n",
        "- https://gaussian37.github.io/dl-keras-number-of-cnn-param/\n",
        "\n",
        "![weight2](https://user-images.githubusercontent.com/96982072/207295813-c05c1789-5749-475c-b5f8-d6f1d6ff0600.png)\n",
        "\n",
        "\n",
        "- input : (150, 150, 3) 형태로 height, width가 각각 150 이고 RGB 값이 3개라고 하겠습니다.\n",
        "\n",
        "- 먼저 (3, 3) 필터 한개에는 3 x 3 = `9`개의 파라미터가 있습니다.\n",
        "\n",
        "- 그리고 입력되는 3-channel 각각에 서로 다른 파라미터들이 입력 되므로 R, G, B 에 해당하는 `3`이 곱해집니다.\n",
        "- 그리고 Conv2D(32, ...) 에서의 32는 32개의 필터를 적용하여 다음 층에서는 채널이 총 32개가 되도록 만든다는 뜻입니다.\n",
        "- 여기에 bias로 더해질 상수가 각각의 채널 마다 존재하므로 32개가 추가로 더해지게 됩니다.\n",
        "\n",
        "\n",
        "- 정리하면, 3 x 3(필터 크기) x 3 (#입력 채널(RGB)) x 32(#출력 채널) + 32(출력 채널 bias) = 896이 됩니다.\n",
        "\n",
        "## AutoEncoder\n",
        "\n",
        "- 입력을 압축 한 후,\n",
        "- 다시 압축해제하여 출력이 입력과 같도록 만듬\n",
        "- class label을 부여해 학습할 필요 없음\n",
        "- 인코더 부분만 따로 떼어내어 네트워크를 구성하면 예측하는 인공지능 구성 가능\n",
        "\n",
        "  ![스크린샷 2022-12-13 오후 7 52 58](https://user-images.githubusercontent.com/96982072/207298845-0828fb89-dd17-4b07-b5c9-e186de5bb1d2.png)\n",
        "\n",
        "\n",
        "## RNN\n",
        "\n",
        "- https://wikidocs.net/22886\n",
        "- 전에 무슨 값이 있었는지가 중요한 데이터들이 있다\n",
        "\n",
        "  - 번역기를 생각해보면 입력은 번역하고자 하는 단어의 시퀀스인 문장\n",
        "\n",
        "- 은닉층의 노드에서 활성화 함수를 통해 나온 결과값을 출력층 방향으로도 보내면서, 다시 은닉층 노드의 다음 계산의 입력으로 보내는 특징  \n",
        "  ![스크린샷 2022-12-13 오후 8 04 05](https://user-images.githubusercontent.com/96982072/207301126-1b8a550f-5856-4ef9-8e00-dcac1386ab90.png)\n",
        "\n",
        "- 코드\n",
        "\n",
        "  ```py\n",
        "\n",
        "  # https://keras.io/api/layers/recurrent_layers/lstm/\n",
        "  # LSTM input shape = (time step -> 횟수, feature -> 종류)\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "      keras.layers.LSTM(10, activation='tanh', input_shape= (28,28)),\n",
        "      keras.layers.Flatten(), # **2D 데이터를 1D 데이터로 변환\n",
        "      keras.layers.Dense(units=10, activation='softmax'),\n",
        "  ])\n",
        "\n",
        "  ```\n",
        "\n",
        "- `keras.layers.LSTM(units, activation='tanh', iinput_shape=(timesteps, input_dim)),`\n",
        "  - `units` = 은닉 상태의 크기를 정의. 메모리 셀이 다음 시점의 메모리 셀과 출력층으로 보내는 값의 크기\n",
        "  - `timesteps` = 입력 시퀀스의 길이(input_length)라고 표현하기도 함. 시점의 수.\n",
        "  - `input_dim` = 입력의 크기, 데이터의 종류   \n",
        "  ![스크린샷 2022-12-13 오후 8 04 00](https://user-images.githubusercontent.com/96982072/207301122-706e820b-bd65-4431-9669-4814b5d156d9.png)\n",
        "\n",
        "## RNN lstm Regularization (L1,L2)\n",
        "\n",
        "- https://wooono.tistory.com/221\n",
        "- https://wandb.ai/sauravm/Regularization-LSTM/reports/Recurrent-Neural-Network-Regularization-With-Keras--VmlldzoxNjkxNzQw\n",
        "\n",
        "- overfitting을 안일어나는 효과\n",
        "  - 성능이 좋아졌다는 것을 뜻하는건 아님\n",
        "\n",
        "-  `layers.LSTM(..., recurrent_regularizer='l1'), `\n",
        "  - Substitute with either 'l1', 'l2' or 'l1_l2'\n",
        "\n",
        "  - `kernel_regularizer` : This argument helps apply regularization to the Kernel Weights Vector.\n",
        "\n",
        "  - `recurrent_regularizer` : This argument helps apply regularization to the Recurrent Kernel Weights Vector.\n",
        "\n",
        "  - `bias_regularizer` : This argument helps apply regularization to the Bias Vector.\n",
        "\n",
        "  - `activity_regularizer` : This argument helps apply regularization to the output of the layer being used.\n",
        "\n"
      ],
      "metadata": {
        "id": "FZn85nZTB4-t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftb9sVzxBvXf"
      },
      "outputs": [],
      "source": []
    }
  ]
}